# -*- coding: utf-8 -*-
"""Travel Insurance.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OTr7_peMOcKkFkKZt1CHYvdSaR0PwE1b
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns



df = pd.read_csv('TravelInsurancePrediction.csv')
#df = df.drop('Unnamed: 0', axis=1)
df = df.rename(columns={'Employment Type':'Employment'})

df

"""L'objectif de ce notebook est de déterminer si le client souscrira à une assurance voyage ou non.
Ainsi, nous effectuerons tout d'abord une analyse exploratoire visuelle et statistique afin de dégager les variables explicatives les plus corrélées à la variable cible, puis nous utiliserons un modèle de machine learning supervisé de type classification (prédiction d’une variable qualitative) pour prédire si le client souscrira à l'assurance ou non. 
Enfin nous utiliserons les techniques d’interprétabilité des modèles de machine learning pour expliquer pourquoi il est plus susceptible de souscrire au produit ou non.

Le dataset est composé de 1987 lignes et 10 colonnes (6 variables numérique et 4 variables catégorielles dont la variable cible TravelInsurance).

'Age' = age des clients
'Employment Type' = secteur métier des clients
'GraduateOrNot' = diplômé ou non 
'AnnualIncome' = revenu annuel
'FamilyMembers'= nombre de personnes dans le foyer
'ChronicDiseases'=  nombre de maladie déclaré
'FrequentFlyer'= voyageur régulier 
'EverTravelledAbroad'= a t il déjà voyagé à l' étranger 
'TravelInsurance' = souscription à l 'assurance
"""

'''
'Age' = age des clients
'Employment Type' = secteur métier des clients
'GraduateOrNot' = diplômé ou non 
'AnnualIncome' = revenu annuel
'FamilyMembers'= nombre de personnes dans le foyer
'ChronicDiseases'=  nombre de maladie déclarée
'FrequentFlyer'= voyageur régulier 
'EverTravelledAbroad'= a t il déjà voyagé à létranger 
'TravelInsurance' = souscription à l assurance

'''

df.columns

df.shape

df.info()

df = df.rename(columns={'Employment Type':'Employment'})

df['TravelInsurance'].value_counts(normalize=True)

df.duplicated().sum()

"""Il y a 738 doublons qui seront conservés. En effet, il est fort probable que des clients aient des caractériques similaires."""

df.isna().sum()

"""Le dataset est complet. Aucune donnée manquante"""

for x in df:
  a = df[x].unique()
  print(a)

"""Analyse statistique"""

def replace_yes_no(cat):
  if cat == 'No':
    return 0
  if cat == 'Yes':
    return 1

def replace_yes_no(cat):
  if cat == 'No':
    return 0
  if cat == 'Yes':
    return 1

df['GraduateOrNot'] = df['GraduateOrNot'].apply(replace_yes_no)

df['FrequentFlyer'] = df['FrequentFlyer'].apply(replace_yes_no)
df['EverTravelledAbroad'] = df['EverTravelledAbroad'].apply(replace_yes_no)

df['Employment Type'] = df['Employment Type'].replace({'Government Sector': 0,
                                                         'Private Sector/Self Employed' : 1	})

df['GraduateOrNot'].unique()

df

cor = df.corr()

fig, ax = plt.subplots(figsize=(10,10))
sns.heatmap(cor, annot=True, ax=ax, cmap='Blues');

'''
Corrélation des variables explicatives avec la variable cible TravelInsurance
Les variables EverTralvelledAbroad et AnnualIncome sont les deux variables les plus corrélées à TravelInsurance suivi de FrequentFlyer

Corrélation des variables explicatives entre elles
Les variables explicatives les plus corrélées sont AnnualIncome à EverTralvelledAbroad, AnnualIncome à FrequentFlyer, AnnualIncome à Employmenttype

'''

"""Analyse de la distribution"""

df.Age.sort_values()

#age 

plt.figure(figsize= (70,70))
sns.displot(df.Age.sort_values(), bins=range(18,40), kde=True, label = 'Age', color='#4cc9f0')
plt.xticks(np.arange(18,40, step=2))
plt.title("Répartition de l'age", fontsize=15)
plt.legend();

sns.set(rc = {'figure.figsize':(5,5)})
sns.countplot(x=df['Employment Type'], palette=['#4cc9f0','#a2d2ff'], order = df['Employment Type'].value_counts(normalize=True).index,)
plt.title('Répartition des métiers', fontsize=10)
plt.legend();

sns.set(rc = {'figure.figsize':(5,5)})
sns.countplot(x=df['GraduateOrNot'], palette=['#4cc9f0','#a2d2ff'], order = df['GraduateOrNot'].value_counts(normalize=True).index,)
plt.title('Répartition des diplômés', fontsize=10)
plt.legend();

df.AnnualIncome.sort_values().unique()

#revenu 

plt.figure(figsize= (70,70))
sns.displot(df.AnnualIncome.sort_values(), kde=True, label = 'AnnualIncome', color='#4cc9f0')
plt.xticks(np.arange(0,(2000000), step=200000))
plt.title("Répartition du revenu annuel en millions", fontsize=15)
plt.legend();

'''
METTRE LA LEGEND EN X
'''

['#03045E','#023E8A', "0077B6","0096C7","00B4D8", "48CAE4"]

sns.set(rc = {'figure.figsize':(5,5)})
sns.countplot(x=df['FamilyMembers'], order = df['FamilyMembers'].value_counts(normalize=True).index,)
plt.title('Nombre de personnes dans le foyer', fontsize=10)
plt.legend();

from scipy.stats import pearsonr 


pd.DataFrame(pearsonr(df['AnnualIncome'], df['TravelInsurance']), index=['pearson_coeff','p-value'], columns=['resultat_test'])

#MACHINE LEARNING

df

X = df.drop('TravelInsurance',axis =1)
y = df.TravelInsurance

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)

#Encoder la variable catégorielle avec OneHotEncoding

from sklearn.preprocessing import OneHotEncoder

col_ohe = ['Employment']


# Le paramètre drop permet d'éviter le problème de multicolinéarité
ohe = OneHotEncoder( drop="first", sparse=False)

X_train_d = pd.get_dummies(
    data=X_train['Employment'],
    columns=['Employment'],
    prefix="e")

X_test_d = pd.get_dummies(
    data=X_test['Employment'],
    columns=['Employment'],
    prefix="e")

X_train = X_train.join(X_train_d)

X_test = X_test.join(X_test_d)

#Standardiser les valeurs numériques

from sklearn.preprocessing import StandardScaler

col_num = ['Age', 'AnnualIncome', 'FamilyMembers']

sc = StandardScaler()

X_train.loc[:,col_num] = sc.fit_transform(X_train[col_num])
X_test.loc[:,col_num] = sc.transform(X_test[col_num])

def replace_yes_no(cat):
  if cat == 'No':
    return 0
  if cat == 'Yes':
    return 1

X_train['FrequentFlyer'] = X_train['FrequentFlyer'].apply(replace_yes_no)
X_train['EverTravelledAbroad'] = X_train['EverTravelledAbroad'].apply(replace_yes_no)
X_train['GraduateOrNot'] = X_train['GraduateOrNot'].apply(replace_yes_no)

X_test['FrequentFlyer'] = X_test['FrequentFlyer'].apply(replace_yes_no)
X_test['EverTravelledAbroad'] = X_test['EverTravelledAbroad'].apply(replace_yes_no)
X_test['GraduateOrNot'] = X_test['GraduateOrNot'].apply(replace_yes_no)

X_train = X_train.drop('Employment', axis=1)

X_test = X_test.drop('Employment', axis=1)

X_train.head(5)

X_test.head(5)

#Random Forest

from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier()
rf.fit(X_train, y_train)

print('Score sur ensemble train', rf.score(X_train, y_train))
print('Score sur ensemble test', rf.score(X_test, y_test))

from sklearn.metrics import classification_report

y_pred = rf.predict(X_test)

pd.crosstab(y_test,y_pred, rownames=['Realité'], colnames=['Prédiction'])

print(classification_report(y_test, y_pred))

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline
feat_importances = pd.DataFrame(rf.feature_importances_, index=X_train.columns, columns=["Importance"])
feat_importances.sort_values(by='Importance', ascending=True, inplace=True)
feat_importances.plot(kind='barh', figsize=(8,6))

#decision tree

from sklearn import tree

clf = tree.DecisionTreeClassifier()
clf.fit(X_train, y_train)

print('Score sur ensemble train', clf.score(X_train, y_train))
print('Score sur ensemble test', clf.score(X_test, y_test))

from sklearn.metrics import classification_report

y_pred = clf.predict(X_test)

print(pd.crosstab(y_test,y_pred, rownames=['Realité'], colnames=['Prédiction']))

print(classification_report(y_test, y_pred))

X_train.columns

from sklearn.tree import plot_tree 

clf = tree.DecisionTreeClassifier(max_depth = 5) 

clf.fit(X_train, y_train)

fig, ax = plt.subplots(figsize=(100, 100))  

plot_tree(clf, 
          feature_names = ['Age', 'GraduateOrNot', 'AnnualIncome', 'FamilyMembers',
       'ChronicDiseases', 'FrequentFlyer', 'EverTravelledAbroad',
       'e_Government Sector', 'e_Private Sector/Self Employed'],
          class_names = ['Yes','No'],
          filled = True, 
          rounded = True)

plt.show()

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline
feat_importances = pd.DataFrame(clf.feature_importances_, index=X_train.columns, columns=["Importance"])
feat_importances.sort_values(by='Importance', ascending=True, inplace=True)
feat_importances.plot(kind='barh', figsize=(8,6))

from sklearn import neighbors
from sklearn import datasets

cla = neighbors.KNeighborsClassifier(n_neighbors=7, metric='minkowski')
cla.fit(X_train, y_train)

y_pred = cla.predict(X_test)

pd.crosstab(y_test, y_pred, rownames=['Classe réelle'], colnames=['Classe prédite'])

score_minkowski = cla.score(X_test, y_test)

print(score_minkowski)

print(classification_report(y_test, y_pred))

knn_m = neighbors.KNeighborsClassifier(n_neighbors=5, metric='manhattan')
knn_m.fit(X_train, y_train)
y_pred_m = knn_m.predict(X_test)

pd.crosstab(y_test, y_pred_m, rownames=['Classe réelle'], colnames=['Classe prédite'])

score_manhattan = knn_m.score(X_test, y_test)

score_manhattan

print(classification_report(y_test, y_pred_m))

import pickle

# Assuming you have a trained model object named 'model'
# Serialize the model
with open('model_rf.pkl', 'wb') as file:
    pickle.dump(rf, file)

#simulation

df.iloc[1,:]

X_train

df[df['TravelInsurance'] == 1]

data = {'Age': -0.228399	, 
        'GraduateOrNot': 1,
        'AnnualIncome' : 1450000,
        'FamilyMembers' : -0.477724	,
        'ChronicDiseases' : 0,
        'FrequentFlyer' : 1,
        'EverTravelledAbroad' : 1,
        'e_Government Sector' : 1	,
        'e_Private Sector/Self Employed': 0,
        }

test1 = pd.DataFrame(data, index=[1])
test1

sc.transform([1450000])

y_pred = rf.predict(test1)

print(y_pred)

df = df.rename(columns={'Unnamed: 0':'nombre'})

df

plt.scatter(df['AnnualIncome'], df['nombre'], s=30, c= df['TravelInsurance'])

t_yes = df[df['TravelInsurance'] == 1]
t_yes

t_yes['AnnualIncome'].mean()

df['FrequentFlyer'].unique().tolist()

